{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a844127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu pymupdf chromadb -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd220c",
   "metadata": {},
   "source": [
    "# PyPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c73ca6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages 33\n",
      "page 1 \n",
      " Bayesian Data Analysis\n",
      "Module 3: Models with more than one parameter\n",
      "Stat 474/574\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/Users/pepo_abdo/Downloads/09_The Normal (mu, sigma) model.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(\"pages\" , len(pages))\n",
    "print(\"page 1 \\n\" , pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3f4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your OpenAI API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99d95691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def warn_once(message, category, filename, lineno, file=None, line=None):\n",
    "    if not warn_once.warned:\n",
    "        warn_once.warned = True\n",
    "        return f'{category.__name__}: {message}'\n",
    "\n",
    "    return None\n",
    "\n",
    "warn_once.warned = False\n",
    "\n",
    "# Filter a specific warning to use the warn_once function\n",
    "warnings.filterwarnings('always', category=RuntimeWarning, message='Your warning message here', append=True)\n",
    "warnings.formatwarning = warn_once\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af317100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-3bDGZSe15HEdD9LnQ9cySNbc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-3bDGZSe15HEdD9LnQ9cySNbc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-3bDGZSe15HEdD9LnQ9cySNbc on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " page 21 \n",
      " Conjugate prior for the normal model\n",
      "Recall that using a non-informative prior, we found that\n",
      "p(µ|σ2,y)∝N(¯y,σ2/n)\n",
      "p(σ2|y)∝Inv−χ2(n−1,s2).\n",
      "Then, factoring p(µ,σ2) =p(µ|σ2)p(σ2) the conjugate prior for σ2\n",
      "would also be scaled inverse χ2and forµ(conditional on σ2) would\n",
      "be normal.\n",
      "Stat 474/574 (ISU) Spring, 2023 22 / 33\n",
      "\n",
      " page 24 \n",
      " Conjugate prior for the normal model (cont’d)\n",
      "Then, p(µ,σ2|y)∝N-Inv-χ2(µn,σ2\n",
      "n/κn;νn,σ2\n",
      "n), where\n",
      "µn=κ0\n",
      "κ0+nµ0+n\n",
      "κ0+n¯y\n",
      "κn=κ0+n\n",
      "νn=ν0+n\n",
      "νnσ2\n",
      "n=ν0σ2\n",
      "0+ (n−1)s2+κ0n\n",
      "κ0+n(¯y−µ0)2.\n",
      "Stat 474/574 (ISU) Spring, 2023 25 / 33\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "faiss_index = FAISS.from_documents(pages , OpenAIEmbeddings())\n",
    "docs = faiss_index.similarity_search(\"What is conjugate prior for mean?\", k=2)\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"\\n page {str(doc.metadata['page'])} \\n {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "788bc4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugate prior for the normal model (cont’d)\n",
      "Interpretation of posterior parameters:\n",
      "As before, µn is a weighted average of the prior mean and the sample\n",
      "mean.\n",
      "The posterior “guess” νnσ2\n",
      "n is the sum of the sample sum of squared\n",
      "deviations, the prior sum of squared deviations, and additional\n",
      "uncertainty due to the diﬀerence between the sample mean and the\n",
      "prior mean.\n",
      "Stat 474/574 (ISU)\n",
      "Spring, 2023\n",
      "26 / 33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"/Users/pepo_abdo/Downloads/09_The Normal (mu, sigma) model.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "data[0]\n",
    "\n",
    "print(data[25].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8e9df",
   "metadata": {},
   "source": [
    "# VectorDB QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce6fc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"/Users/pepo_abdo/Downloads/09_The Normal (mu, sigma) model.pdf\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42bac97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000 , chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(documents , embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e75b98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    "    \n",
    ")\n",
    "\n",
    "from langchain.schema import (\n",
    "AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "system_template = \"\"\"\n",
    "Use the following pieces of context to answer the users question.\n",
    "if you don't know the answer , Just say that you don't know, don't try to make up an answer.\n",
    "-----------\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd64577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "qa = VectorDBQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\", vectorstore=docsearch, chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1becfd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = qa.run(\"what is joint posterior distribution, conditional posterior, and marginal posterior of normal? Provide the notations and an english translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83e8235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The joint posterior distribution of a normal model, denoted as p(µ, σ2|y), represents the probability distribution of\n",
      "the parameters µ and σ2 given the observed data y.  The conditional posterior distribution of µ given σ2 and y, denoted\n",
      "as p(µ|σ2, y), represents the probability distribution of the parameter µ given the observed data y and the known value\n",
      "of σ2.  The marginal posterior distribution of σ2 given y, denoted as p(σ2|y), represents the probability distribution\n",
      "of the parameter σ2 given the observed data y. It is obtained by integrating the joint posterior distribution p(µ, σ2|y)\n",
      "with respect to µ.  Notations: - Joint posterior distribution: p(µ, σ2|y) - Conditional posterior distribution of µ\n",
      "given σ2 and y: p(µ|σ2, y) - Marginal posterior distribution of σ2 given y: p(σ2|y)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import textwrap\n",
    "\n",
    "def wrap_text(text , width=120):\n",
    "    return \"\\n\".join(textwrap.wrap(text,width))\n",
    "print(wrap_text(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc19f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutiple docs\n",
    "\n",
    "import os\n",
    "pdfs = os.listdir('pdfs')\n",
    "loaders = []\n",
    "\n",
    "for pdf in pdfs:\n",
    "    \n",
    "    loaders.append(PyMuPDFLoader(f\"pdfs/{pdf}\"))\n",
    "\n",
    "docs = []\n",
    "\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ce5677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='1\\n1\\nARTIFICIAL \\nINTELLIGENCE\\nIntroduction\\n2\\nOutline\\n\\uf06c What is AI?\\n\\uf06c A brief history\\n\\uf06c What can AI do?\\n', metadata={'source': 'pdfs/lecture01-into-2up.pdf', 'file_path': 'pdfs/lecture01-into-2up.pdf', 'page': 0, 'total_pages': 8, 'format': 'PDF 1.5', 'title': '', 'author': 'Jin Tian', 'subject': '', 'keywords': '', 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 15.0 (Windows)', 'creationDate': \"D:20210825102010-05'00'\", 'modDate': \"D:20210825102106-05'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38211929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
