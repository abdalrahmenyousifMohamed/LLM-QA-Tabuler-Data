{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = TapasTokenizer.from_pretrained('google/tapas-base-finetuned-wtq')\n",
    "model = TapasForQuestionAnswering.from_pretrained('google/tapas-base-finetuned-wtq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a large table with more than 300 rows\n",
    "data = {\n",
    "    'Actors': [\"Actor \" + str(i) for i in range(301)],\n",
    "    'Age': [str(20 + i % 40) for i in range(301)],\n",
    "    'Number of Movies': [str(10 + i % 50) for i in range(301)]\n",
    "}\n",
    "large_table = pd.DataFrame.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large_table.to_csv('large_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_table(table, chunk_size=50):\n",
    "    return [table[i:i + chunk_size] for i in range(0, table.shape[0], chunk_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def compute_prediction_sequence(model, data, device):\n",
    "  \"\"\"Computes predictions using model's answers to the previous questions.\"\"\"\n",
    "\n",
    "  # prepare data\n",
    "  input_ids = data[\"input_ids\"].to(device)\n",
    "  attention_mask = data[\"attention_mask\"].to(device)\n",
    "  token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "\n",
    "  all_logits = []\n",
    "  prev_answers = None\n",
    "\n",
    "  num_batch = data[\"input_ids\"].shape[0]\n",
    "\n",
    "  for idx in range(num_batch):\n",
    "\n",
    "    if prev_answers is not None:\n",
    "        coords_to_answer = prev_answers[idx]\n",
    "        # Next, set the label ids predicted by the model\n",
    "        prev_label_ids_example = token_type_ids_example[:,3] # shape (seq_len,)\n",
    "        model_label_ids = np.zeros_like(prev_label_ids_example.cpu().numpy()) # shape (seq_len,)\n",
    "\n",
    "        # for each token in the sequence:\n",
    "        token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "        for i in range(model_label_ids.shape[0]):\n",
    "          segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "          col_id = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "          row_id = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "          if row_id >= 0 and col_id >= 0 and segment_id == 1:\n",
    "            model_label_ids[i] = int(coords_to_answer[(col_id, row_id)])\n",
    "\n",
    "        # set the prev label ids of the example (shape (1, seq_len) )\n",
    "        token_type_ids_example[:,3] = torch.from_numpy(model_label_ids).type(torch.long).to(device)\n",
    "\n",
    "    prev_answers = {}\n",
    "    # get the example\n",
    "    input_ids_example = input_ids[idx] # shape (seq_len,)\n",
    "    attention_mask_example = attention_mask[idx] # shape (seq_len,)\n",
    "    token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "    # forward pass to obtain the logits\n",
    "    outputs = model(input_ids=input_ids_example.unsqueeze(0),\n",
    "                    attention_mask=attention_mask_example.unsqueeze(0),\n",
    "                    token_type_ids=token_type_ids_example.unsqueeze(0))\n",
    "    logits = outputs.logits\n",
    "    all_logits.append(logits)\n",
    "\n",
    "    # convert logits to probabilities (which are of shape (1, seq_len))\n",
    "    dist_per_token = torch.distributions.Bernoulli(logits=logits)\n",
    "    probabilities = dist_per_token.probs * attention_mask_example.type(torch.float32).to(dist_per_token.probs.device)\n",
    "\n",
    "    # Compute average probability per cell, aggregating over tokens.\n",
    "    # Dictionary maps coordinates to a list of one or more probabilities\n",
    "    coords_to_probs = collections.defaultdict(list)\n",
    "    prev_answers = {}\n",
    "    for i, p in enumerate(probabilities.squeeze().tolist()):\n",
    "      segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "      col = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "      row = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "      if col >= 0 and row >= 0 and segment_id == 1:\n",
    "        coords_to_probs[(col, row)].append(p)\n",
    "\n",
    "    # Next, map cell coordinates to 1 or 0 (depending on whether the mean prob of all cell tokens is > 0.5)\n",
    "    coords_to_answer = {}\n",
    "    for key in coords_to_probs:\n",
    "      coords_to_answer[key] = np.array(coords_to_probs[key]).mean() > 0.5\n",
    "    prev_answers[idx+1] = coords_to_answer\n",
    "\n",
    "  logits_batch = torch.cat(tuple(all_logits), 0)\n",
    "\n",
    "  return logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def score_chunk_relevance(chunk, query, vectorizer):\n",
    "    # Combine the chunk's text into a single string\n",
    "    # print(chunk)\n",
    "    chunk_text = str(chunk)\n",
    "    query_text = str(query)\n",
    "    \n",
    "    # Transform texts to TF-IDF vectors\n",
    "    texts = [chunk_text, query_text]\n",
    "    tfidf_matrix = vectorizer.transform(texts)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    \n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "# print(chunk)\n",
    "vectorizer = TfidfVectorizer().fit([\" \".join(large_table.fillna('').values.flatten())])\n",
    "def chunk_table_with_context(table, chunk_size=50, overlap=1):\n",
    "    chunks = []\n",
    "    for i in range(0, table.shape[0], chunk_size):\n",
    "        start_idx = max(0, i - overlap)\n",
    "        end_idx = min(table.shape[0], i + chunk_size)\n",
    "        chunks.append(table.iloc[start_idx:end_idx])\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Downloading dask-2024.5.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click>=8.1 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from dask) (8.1.7)\n",
      "Collecting cloudpickle>=1.5.0 (from dask)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from dask) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from dask) (24.0)\n",
      "Collecting partd>=1.2.0 (from dask)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from dask) (6.0.1)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from dask) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->dask) (3.17.0)\n",
      "Collecting locket (from partd>=1.2.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading dask-2024.5.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: toolz, locket, cloudpickle, partd, dask\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.2.2\n",
      "    Uninstalling cloudpickle-1.2.2:\n",
      "      Successfully uninstalled cloudpickle-1.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 3.23.0 requires pillow, which is not installed.\n",
      "streamlit 1.26.0 requires pillow<10,>=7.1.0, which is not installed.\n",
      "gym 0.15.3 requires cloudpickle~=1.2.0, but you have cloudpickle 3.0.0 which is incompatible.\n",
      "streamlit 1.26.0 requires importlib-metadata<7,>=1.4, but you have importlib-metadata 7.1.0 which is incompatible.\n",
      "streamlit 1.26.0 requires packaging<24,>=16.8, but you have packaging 24.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cloudpickle-3.0.0 dask-2024.5.2 locket-1.0.0 partd-1.4.2 toolz-0.12.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answers: [<NA>, <NA>, '100  Actor 100  40               10', <NA>, <NA>, <NA>, <NA>]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "import torch\n",
    "from io import StringIO\n",
    "from dask import dataframe as dd\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def process_chunk(model, tokenizer, chunk, queries):\n",
    "    model.to(device)\n",
    "    # Check relevance\n",
    "    relevance_score = score_chunk_relevance(chunk, queries, vectorizer)\n",
    "    if relevance_score < 0.66:  # Threshold for relevance\n",
    "        return None\n",
    "    df = pd.read_csv(StringIO(chunk))\n",
    "    inputs = tokenizer(table=df, queries=queries, padding='max_length', return_tensors=\"pt\", truncation=True)\n",
    "    logits = compute_prediction_sequence(model, inputs, device)\n",
    "    predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())\n",
    "\n",
    "    if predicted_answer_coordinates[0]:\n",
    "        row, col = predicted_answer_coordinates[0][0]\n",
    "        chunk = pd.read_csv(StringIO(chunk))\n",
    "        return chunk.iloc[row, col]\n",
    "\n",
    "# Assuming `large_table` and `chunk_table_with_context` are defined elsewhere\n",
    "\n",
    "# Chunk the large table with context preservation\n",
    "chunks = chunk_table_with_context(large_table)\n",
    "\n",
    "# Convert to Dask DataFrame\n",
    "dask_chunks = dd.from_pandas(pd.DataFrame({'chunks': chunks}), npartitions=len(chunks))\n",
    "\n",
    "# Define queries\n",
    "queries = [\"actor 100 number of movies\"]\n",
    "\n",
    "# Process each chunk in parallel\n",
    "results = dask_chunks.map_partitions(lambda df: df.apply(lambda row: process_chunk(model, tokenizer, row['chunks'], queries), axis=1))\n",
    "\n",
    "# Compute the results\n",
    "# computed_results = results.compute()\n",
    "\n",
    "# Filter out None values and print results\n",
    "answers = [res for res in results if res is not None]\n",
    "print(f\"Predicted answers: {answers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit app\n",
    "st.title('TAPAS Question Answering on Tables')\n",
    "\n",
    "# File uploader for CSV files\n",
    "uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Read the CSV file\n",
    "    large_table = pd.read_csv(uploaded_file)\n",
    "    st.write(\"Uploaded Table:\")\n",
    "    st.write(large_table)\n",
    "    \n",
    "    queries = st.text_input(\"Enter your question:\", \"How many movies has Actor 150 acted in?\")\n",
    "    \n",
    "    if st.button(\"Get Answer\"):\n",
    "        # Initialize TF-IDF Vectorizer\n",
    "        vectorizer = TfidfVectorizer().fit([\" \".join(large_table.astype(str).fillna('').values.flatten())])\n",
    "        \n",
    "        # Chunk the table\n",
    "        chunks = chunk_table_with_context(large_table)\n",
    "        dask_chunks = dd.from_pandas(pd.DataFrame({'chunks': chunks}), npartitions=len(chunks))\n",
    "        \n",
    "        # Process each chunk\n",
    "        results = dask_chunks.map_partitions(lambda df: df.apply(lambda row: process_chunk(model, tokenizer, row['chunks'], [queries], device), axis=1)).compute()\n",
    "        answers = [res for res in results if res is not None]\n",
    "        \n",
    "        st.write(f\"Predicted answers: {answers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant-client\n",
      "  Using cached qdrant_client-1.9.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from qdrant-client) (1.49.1)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
      "  Downloading grpcio_tools-1.64.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from qdrant-client) (1.23.0)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from qdrant-client) (1.10.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from qdrant-client) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from grpcio>=1.41.0->qdrant-client) (1.16.0)\n",
      "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
      "  Using cached protobuf-5.27.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
      "  Downloading grpcio-1.64.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: setuptools in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.7.2)\n",
      "Requirement already satisfied: anyio in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from pydantic>=1.10.8->qdrant-client) (4.12.1)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.0)\n",
      "Using cached qdrant_client-1.9.1-py3-none-any.whl (229 kB)\n",
      "Downloading grpcio_tools-1.64.1-cp39-cp39-macosx_10_9_universal2.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.64.1-cp39-cp39-macosx_10_9_universal2.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached protobuf-5.27.1-cp38-abi3-macosx_10_9_universal2.whl (412 kB)\n",
      "Installing collected packages: protobuf, portalocker, grpcio, grpcio-tools, qdrant-client\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.2\n",
      "    Uninstalling protobuf-3.20.2:\n",
      "      Successfully uninstalled protobuf-3.20.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.49.1\n",
      "    Uninstalling grpcio-1.49.1:\n",
      "      Successfully uninstalled grpcio-1.49.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "googleapis-common-protos 1.57.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.1 which is incompatible.\n",
      "onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 5.27.1 which is incompatible.\n",
      "open-clip-torch 2.16.0 requires protobuf<4, but you have protobuf 5.27.1 which is incompatible.\n",
      "opentelemetry-proto 1.24.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.27.1 which is incompatible.\n",
      "ray 2.3.0 requires grpcio<=1.49.1,>=1.32.0; python_version < \"3.10\" and sys_platform == \"darwin\", but you have grpcio 1.64.1 which is incompatible.\n",
      "skl2onnx 1.13 requires scikit-learn<=1.1.1, but you have scikit-learn 1.4.1.post1 which is incompatible.\n",
      "streamlit 1.26.0 requires importlib-metadata<7,>=1.4, but you have importlib-metadata 7.1.0 which is incompatible.\n",
      "streamlit 1.26.0 requires packaging<24,>=16.8, but you have packaging 24.0 which is incompatible.\n",
      "streamlit 1.26.0 requires pillow<10,>=7.1.0, but you have pillow 10.3.0 which is incompatible.\n",
      "streamlit 1.26.0 requires protobuf<5,>=3.20, but you have protobuf 5.27.1 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.27.1 which is incompatible.\n",
      "tensorboardx 2.6 requires protobuf<4,>=3.8.0, but you have protobuf 5.27.1 which is incompatible.\n",
      "tensorflow-metadata 1.11.0 requires protobuf<4,>=3.13, but you have protobuf 5.27.1 which is incompatible.\n",
      "wandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.19.0; sys_platform != \"linux\", but you have protobuf 5.27.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed grpcio-1.64.1 grpcio-tools-1.64.1 portalocker-2.8.2 protobuf-5.27.1 qdrant-client-1.9.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install pypdf\n",
    "# !pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actors</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of Movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Actor 50</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actors Age Number of Movies\n",
       "50  Actor 50  30               10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_table.loc[large_table['Actors'] == 'Actor 50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "iloc cannot enlarge its target object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Tokenize training data by chunks\u001b[39;00m\n\u001b[0;32m     13\u001b[0m train_chunks \u001b[38;5;241m=\u001b[39m chunk_table(large_table)\n\u001b[1;32m---> 14\u001b[0m train_inputs_list \u001b[38;5;241m=\u001b[39m [tokenizer(table\u001b[38;5;241m=\u001b[39mchunk, queries\u001b[38;5;241m=\u001b[39mtrain_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m train_chunks]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create dataset\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTableDataset\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:575\u001b[0m, in \u001b[0;36mTapasTokenizer.__call__\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(queries, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m    576\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    577\u001b[0m         queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m    578\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    579\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    580\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    581\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    582\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    583\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    584\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    585\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    586\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    587\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    588\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    589\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    590\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    591\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    592\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    594\u001b[0m     )\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m    597\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    598\u001b[0m         query\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    615\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:693\u001b[0m, in \u001b[0;36mTapasTokenizer.batch_encode_plus\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    690\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    691\u001b[0m     )\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m    694\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[0;32m    695\u001b[0m     queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m    696\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    697\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    698\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    699\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    700\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    701\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    702\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    703\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    704\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    705\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    706\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    707\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    708\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m    709\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    710\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    712\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:760\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_encode_plus\u001b[1;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m     queries[idx] \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    758\u001b[0m     queries_tokens\u001b[38;5;241m.\u001b[39mappend(query_tokens)\n\u001b[1;32m--> 760\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_prepare_for_model(\n\u001b[0;32m    761\u001b[0m     table,\n\u001b[0;32m    762\u001b[0m     queries,\n\u001b[0;32m    763\u001b[0m     tokenized_table\u001b[38;5;241m=\u001b[39mtable_tokens,\n\u001b[0;32m    764\u001b[0m     queries_tokens\u001b[38;5;241m=\u001b[39mqueries_tokens,\n\u001b[0;32m    765\u001b[0m     answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates,\n\u001b[0;32m    766\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    767\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    768\u001b[0m     answer_text\u001b[38;5;241m=\u001b[39manswer_text,\n\u001b[0;32m    769\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    770\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    771\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m    772\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m    773\u001b[0m     prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    774\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    775\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    776\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m    777\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    778\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    779\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    780\u001b[0m )\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m BatchEncoding(batch_outputs)\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:815\u001b[0m, in \u001b[0;36mTapasTokenizer._batch_prepare_for_model\u001b[1;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(raw_queries, queries_tokens, answer_coordinates, answer_text)):\n\u001b[0;32m    814\u001b[0m     raw_query, query_tokens, answer_coords, answer_txt \u001b[38;5;241m=\u001b[39m example\n\u001b[1;32m--> 815\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[0;32m    816\u001b[0m         raw_table,\n\u001b[0;32m    817\u001b[0m         raw_query,\n\u001b[0;32m    818\u001b[0m         tokenized_table\u001b[38;5;241m=\u001b[39mtokenized_table,\n\u001b[0;32m    819\u001b[0m         query_tokens\u001b[38;5;241m=\u001b[39mquery_tokens,\n\u001b[0;32m    820\u001b[0m         answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coords,\n\u001b[0;32m    821\u001b[0m         answer_text\u001b[38;5;241m=\u001b[39manswer_txt,\n\u001b[0;32m    822\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m    823\u001b[0m         padding\u001b[38;5;241m=\u001b[39mPaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\u001b[38;5;241m.\u001b[39mvalue,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m    825\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m    826\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    827\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we pad in batch afterwards\u001b[39;00m\n\u001b[0;32m    828\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m    829\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m    830\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m    831\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# We convert the whole batch to tensors at the end\u001b[39;00m\n\u001b[0;32m    832\u001b[0m         prepend_batch_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    834\u001b[0m         prev_answer_coordinates\u001b[38;5;241m=\u001b[39manswer_coordinates[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    835\u001b[0m         prev_answer_text\u001b[38;5;241m=\u001b[39manswer_text[index \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m batch_outputs:\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:1154\u001b[0m, in \u001b[0;36mTapasTokenizer.prepare_for_model\u001b[1;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     prev_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_answer_ids(\n\u001b[0;32m   1149\u001b[0m         column_ids, row_ids, table_data, prev_answer_text, prev_answer_coordinates\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;66;03m# FIRST: parse both the table and question in terms of numeric values\u001b[39;00m\n\u001b[1;32m-> 1154\u001b[0m raw_table \u001b[38;5;241m=\u001b[39m add_numeric_table_values(raw_table)\n\u001b[0;32m   1155\u001b[0m raw_query \u001b[38;5;241m=\u001b[39m add_numeric_values_to_question(raw_query)\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;66;03m# SECOND: add numeric-related features (and not parse them in these functions):\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\transformers\\models\\tapas\\tokenization_tapas.py:2751\u001b[0m, in \u001b[0;36madd_numeric_table_values\u001b[1;34m(table, min_consolidation_fraction, debug_info)\u001b[0m\n\u001b[0;32m   2749\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_index, row \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m   2750\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_index, cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(row):\n\u001b[1;32m-> 2751\u001b[0m         table\u001b[38;5;241m.\u001b[39miloc[row_index, col_index] \u001b[38;5;241m=\u001b[39m Cell(text\u001b[38;5;241m=\u001b[39mcell)\n\u001b[0;32m   2753\u001b[0m \u001b[38;5;66;03m# Third, add numeric_value attributes to these Cell objects\u001b[39;00m\n\u001b[0;32m   2754\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col_index, column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(table\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\pandas\\core\\indexing.py:908\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    906\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m    907\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_setitem_indexer(key)\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m    911\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\bg-eg\\miniconda3\\envs\\myenvironment\\Lib\\site-packages\\pandas\\core\\indexing.py:1646\u001b[0m, in \u001b[0;36m_iLocIndexer._has_valid_setitem_indexer\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(i):\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ax):\n\u001b[1;32m-> 1646\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Dummy data for weak supervision\n",
    "train_data = {\n",
    "    'queries': [\"How many movies has Actor 50 acted in?\", \"How old is Actor 1?\"],\n",
    "    'answers': [10, 21]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Tokenize training data by chunks\n",
    "train_chunks = chunk_table(large_table)\n",
    "train_inputs_list = [tokenizer(table=chunk, queries=train_df['queries'].tolist(), padding='max_length', return_tensors=\"pt\", truncation=True) for chunk in train_chunks]\n",
    "\n",
    "# Create dataset\n",
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs_list, answers):\n",
    "        self.inputs_list = inputs_list\n",
    "        self.answers = answers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.answers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.inputs_list[idx].items()}\n",
    "        item['labels'] = torch.tensor(self.answers[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = TableDataset(train_inputs_list, train_df['answers'].tolist())\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mOllama\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbase_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://localhost:11434'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'llama2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmirostat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmirostat_eta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmirostat_tau\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_ctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_gpu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_thread\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_predict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrepeat_last_n\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrepeat_penalty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtemperature\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtfs_z\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtop_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtop_p\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msystem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtemplate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mheaders\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackHandler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallback_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Ollama locally runs large language models.\n",
      "\n",
      "To use, follow the instructions at https://ollama.ai/.\n",
      "\n",
      "Example:\n",
      "    .. code-block:: python\n",
      "\n",
      "        from langchain_community.llms import Ollama\n",
      "        ollama = Ollama(model=\"llama2\")\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Create a new model by parsing and validating input data from keyword arguments.\n",
      "\n",
      "Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniforge3/envs/mlenv/lib/python3.9/site-packages/langchain_community/llms/ollama.py\n",
      "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "Ollama?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepo_abdo/miniforge3/envs/mlenv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I take a sip of my latte as I casually glance over at the couple sitting at the next table, eavesdropping on their conversation about space exploration. They seem engrossed in their discussion, oblivious to my attention.\n",
      "\n",
      "\"...and then we'd have to develop new propulsion systems,\" one of them says. \"Something that could withstand the stresses of interstellar travel.\"\n",
      "\n",
      "I lean in slightly, intrigued by the topic. The other person nods thoughtfully. \"I agree, but what about radiation protection? We can't just expose our astronauts to all that cosmic radiation.\"\n",
      "\n",
      "Their conversation sparks my imagination. I start daydreaming about what it would be like to travel through space, visiting distant planets and encountering new forms of life. The possibilities seem endless.\n",
      "\n",
      "As they continue discussing the challenges of space exploration, I find myself mentally designing a futuristic spaceship, complete with advanced life support systems and gravity manipulation technology. The café's tranquil atmosphere fades into the background as my mind becomes lost in the wonders of the cosmos.\n",
      "\n",
      "Just as I'm getting caught up in the excitement, the couple finishes their conversation and gets up to leave. As they walk out of the café, one of them glances over at me and smiles, perhaps sensing that I was listening in on their discussion. I quickly look away, feeling a bit guilty for my eavesdropping ways.\n",
      "\n",
      "But as I return to my latte, I can't help but feel a renewed sense of wonder and curiosity about the vastness of space and our place within it. The café's peaceful ambiance returns, but now it's infused with a sense of adventure and possibility.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
